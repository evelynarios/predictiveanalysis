# -*- coding: utf-8 -*-
"""ML_Terapan.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tdm5ao-n0stdW3UCAr5l5xV7KDcu1nKP

# **Final Exam Score Prediction - Regression**

## **Import Library**
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.compose import make_column_selector as selector
from sklearn.pipeline import Pipeline
from sklearn.metrics import r2_score, mean_squared_error,  mean_absolute_error
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.neighbors import KNeighborsRegressor
from google.colab import files

"""## **Data loading**"""

files.upload()  # Upload file kaggle.json

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Download dataset
!kaggle datasets download -d jayaantanaath/student-habits-vs-academic-performance

!unzip student-habits-vs-academic-performance.zip

"""## **Data Understanding**"""

# Nama file sesuai isi zip
df = pd.read_csv("student_habits_performance.csv")

# Tampilan 5 baris pertama
df.head()

df.isnull().sum()

df.duplicated().sum()

"""## **Filling Missing Values**"""

df['parental_education_level'].fillna(df['parental_education_level'].mode()[0], inplace=True)

df.info()

df.describe()

"""## **EDA**"""

plt.figure(figsize=(15, 5))

# Gender Distribution
plt.subplot(1, 3, 1)
df['gender'].value_counts().plot(
    kind='pie',
    autopct="%.2f%%",
    colors=['skyblue', 'steelblue', 'lightcoral'],
    startangle=90
)
plt.title('Gender Distribution')
plt.ylabel('')  # Menghilangkan label Y

# Part-time Job Distribution
plt.subplot(1, 3, 2)
df['part_time_job'].value_counts().plot(
    kind='pie',
    autopct="%.2f%%",
    colors=['lightgreen', 'mediumseagreen', 'darkgreen'],
    startangle=90
)
plt.title('Part-time Job Distribution')
plt.ylabel('')

# Diet Quality Distribution
plt.subplot(1, 3, 3)
df['diet_quality'].value_counts().plot(
    kind='pie',
    autopct="%.2f%%",
    colors=['lightyellow', 'gold', 'orange'],
    startangle=90
)
plt.title('Diet Quality Distribution')
plt.ylabel('')

plt.tight_layout()
plt.show()

plt.figure(figsize=(15, 5))

# Parental Education Level Distribution
plt.subplot(1, 3, 1)
df['parental_education_level'].value_counts().plot(
    kind='pie',
    autopct="%.2f%%",
    colors=['skyblue', 'royalblue', 'mediumslateblue', 'orange'],
    startangle=90
)
plt.title('Parental Education Level')
plt.ylabel('')

# Internet Quality Distribution
plt.subplot(1, 3, 2)
df['internet_quality'].value_counts().plot(
    kind='pie',
    autopct="%.2f%%",
    colors=['skyblue', 'steelblue', 'plum'],
    startangle=90
)
plt.title('Internet Quality')
plt.ylabel('')

# Extracurricular Participation Distribution
plt.subplot(1, 3, 3)
df['extracurricular_participation'].value_counts().plot(
    kind='pie',
    autopct="%.2f%%",
    colors=['skyblue', 'tomato'],
    startangle=90
)
plt.title('Extracurricular Participation')
plt.ylabel('')

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(18, 5))

# Plot 1: Study Hours vs Exam Score
plt.subplot(1, 3, 1)
sns.scatterplot(
    x='study_hours_per_day',
    y='exam_score',
    hue='gender',
    data=df,
    s=90,
    alpha=0.8,
    palette='tab10'
)
plt.title('Study Hours vs Exam Score', fontsize=12, fontweight='bold')
plt.xlabel('Study Hours/Day')
plt.ylabel('Exam Score')
plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.5)
plt.legend(title='Gender', loc='lower right')

# Plot 2: Social Media Hours vs Exam Score
plt.subplot(1, 3, 2)
sns.scatterplot(
    x='social_media_hours',
    y='exam_score',
    data=df,
    color='dodgerblue',
    s=90,
    alpha=0.7
)
plt.title('Social Media Hours vs Exam Score', fontsize=12, fontweight='bold')
plt.xlabel('Social Media Hours')
plt.ylabel('')
plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.5)

# Plot 3: Sleep Hours vs Exam Score
plt.subplot(1, 3, 3)
sns.scatterplot(
    x='sleep_hours',
    y='exam_score',
    data=df,
    color='dodgerblue',
    s=90,
    alpha=0.7
)
plt.title('Sleep Hours vs Exam Score', fontsize=12, fontweight='bold')
plt.xlabel('Sleep Hours')
plt.ylabel('')
plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.5)

plt.tight_layout()
plt.show()

plt.figure(figsize=(5,5))
ax = sns.barplot(x='gender', y='exam_score', data=df, ci=None)

for p in ax.patches:
    height = p.get_height()
    ax.text(p.get_x() + p.get_width()/2., height + 1,
            f'{height:.1f}', ha="center", fontsize=12)
plt.title('Gender vs Exam Score', fontsize=12)
plt.xlabel('Gender')
plt.ylabel('Average Exam Score')
plt.grid()
plt.show()

plt.figure(figsize=(10, 5))
sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='Blues_r')
plt.title('Correlation Heatmap', fontsize=14)
plt.show()

plt.figure(figsize=(10,5))
sns.distplot(x=df['exam_score'], hist=False)
plt.grid()
plt.show()

"""## **Feature Selection & Categorization**"""

# Drop kolom student_id dan target
X = df.drop(['student_id', 'exam_score'], axis=1)
y = df['exam_score']

# Kolom kategorikal dan numerikal
categorical_cols = [
    'gender',
    'part_time_job',
    'diet_quality',
    'parental_education_level',
    'internet_quality',
    'extracurricular_participation'
]

numerical_cols = [
    'age',
    'study_hours_per_day',
    'social_media_hours',
    'netflix_hours',
    'attendance_percentage',
    'sleep_hours',
    'exercise_frequency',
    'mental_health_rating'
]

"""## **Preprocessing & Split Data**"""

# Preprocessor: Standarisasi numerik + OneHot kategorikal
preprocessor = ColumnTransformer([
    ('num', StandardScaler(), numerical_cols),
    ('cat', OneHotEncoder(drop='first'), categorical_cols)
])

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Fit dan transform data training
X_train_transformed = preprocessor.fit_transform(X_train)

# Ambil nama fitur dari OneHotEncoder
ohe = preprocessor.named_transformers_['cat']
ohe_feature_names = ohe.get_feature_names_out(categorical_cols)

# Gabungkan nama fitur numerik dan fitur hasil encoding
all_feature_names = numerical_cols + list(ohe_feature_names)

# Buat DataFrame dari hasil transformasi
X_train_processed_df = pd.DataFrame(X_train_transformed, columns=all_feature_names)

# Tampilkan 5 baris pertama
X_train_processed_df.head()

"""## **Modelling**"""

# Model yang akan dibangun
models = {
    'Linear Regression': LinearRegression(),
    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),
    'K-Nearest Neighbors': KNeighborsRegressor()
}

# Simpan pipeline dan prediksi setiap model
trained_models = {}
predictions = {}

for name, model in models.items():
    # Pipeline: preprocessing + model
    pipe = Pipeline([
        ('preprocess', preprocessor),
        ('regressor', model)
    ])

    # Training
    pipe.fit(X_train, y_train)

    # Simpan pipeline & prediksi
    trained_models[name] = pipe
    predictions[name] = pipe.predict(X_test)

"""## **Evaluation**"""

# Simpan skor evaluasi
results = []

for name, y_pred in predictions.items():
    r2 = r2_score(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)

    results.append({
        'Model': name,
        'R2 Score': r2,
        'MSE': mse,
        'MAE': mae
    })

    # Visualisasi
    plt.figure(figsize=(8, 4))
    plt.plot(y_test.values, label='Actual', color='black', linewidth=2)
    plt.plot(y_pred, label='Predicted', color='blue', linestyle='dashed')
    plt.title(f"{name} - Actual vs Predicted")
    plt.xlabel("Data Index")
    plt.ylabel("Exam Score")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

# Tampilkan hasil evaluasi
results_df = pd.DataFrame(results).sort_values(by="R2 Score", ascending=False)
print("Perbandingan Evaluasi Model:")
print(results_df.to_string(index=False))

import seaborn as sns
import matplotlib.pyplot as plt

# Set seaborn style dan palet biru
sns.set(style="whitegrid")
blue_palette = sns.color_palette("Blues_d", n_colors=len(results_df))

# Plot per metrik dengan bar yang presisi dan warna biru
metrics = ['R2 Score', 'MSE', 'MAE']

for metric in metrics:
    plt.figure(figsize=(6, 4))
    ax = sns.barplot(
        data=results_df,
        x='Model',
        y=metric,
        palette=blue_palette
    )

    # Tambahkan nilai di atas setiap batang
    for p in ax.patches:
        ax.annotate(
            f'{p.get_height():.3f}',
            (p.get_x() + p.get_width() / 2., p.get_height()),
            ha='center', va='bottom',
            fontsize=10, color='black',
            xytext=(0, 5),
            textcoords='offset points'
        )

    plt.title(f'Perbandingan {metric} antar Model', fontsize=14)
    plt.ylabel(metric, fontsize=12)
    plt.xlabel('Model', fontsize=12)
    plt.xticks(rotation=0, fontsize=10)
    plt.yticks(fontsize=10)
    plt.tight_layout()
    plt.show()

"""**Insight:** <br>
Berdasarkan hasil evaluasi, model Linear Regression memberikan performa terbaik dibandingkan Random Forest dan K-Nearest Neighbors. Hal ini ditunjukkan oleh nilai RÂ² Score yang paling tinggi (0.897) serta nilai MSE dan MAE yang paling rendah. Artinya, Linear Regression mampu membuat prediksi yang paling akurat dan stabil untuk dataset ini.
"""

best_model = trained_models['Linear Regression']

# Mengambil koefisien regresi dan fitur dari pipeline
regressor = best_model.named_steps['regressor']
feature_names = preprocessor.get_feature_names_out()
coefficients = regressor.coef_

coef_df = pd.DataFrame({
    'Feature': feature_names,
    'Coefficient': coefficients
}).sort_values(by='Coefficient', ascending=False)

print(coef_df)

# Ambil pipeline model terbaik
best_model = trained_models['Linear Regression']

# Ambil koefisien dan nama fitur dari pipeline
regressor = best_model.named_steps['regressor']
feature_names = preprocessor.get_feature_names_out()
coefficients = regressor.coef_

# Buat DataFrame
coef_df = pd.DataFrame({
    'Feature': feature_names,
    'Coefficient': coefficients
}).sort_values(by='Coefficient', ascending=True)

# Visualisasi
plt.figure(figsize=(10, 6))
sns.barplot(x='Coefficient', y='Feature', data=coef_df, palette='coolwarm')
plt.title('Pengaruh Fitur terhadap Nilai Ujian (Exam Score) (Linear Regression)')
plt.xlabel('Koefisien')
plt.ylabel('Fitur')
plt.axvline(x=0, color='gray', linestyle='--')
plt.tight_layout()
plt.show()